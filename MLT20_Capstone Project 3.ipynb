{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L3T20 - Capstone Project 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries & loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Load dataset  and key from imdb set\n",
    "\n",
    "(trainX, trainY), (testX, testY) = imdb.load_data(num_words = 10000)\n",
    "word_dict = imdb.get_word_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key for review generation\n",
    "\n",
    "offset=3   # word index offset\n",
    "word_dict = {k:(v + offset) for k, v in word_dict.items()}\n",
    "word_dict[\"<PAD>\"] = 0\n",
    "word_dict[\"<START>\"] = 1\n",
    "word_dict[\"<UNK>\"] = 2\n",
    "word_dict[\"<UNUSED>\"] = 3\n",
    "id_dict = {value:key for key, value in word_dict.items()}\n",
    "\n",
    "# Create review print function\n",
    "\n",
    "def print_rev(rev_data):\n",
    "    print('\\n=================================================')\n",
    "    print(f'Sample = {i} | Length = {len(rev_data)}')\n",
    "    print('=================================================')\n",
    "    print(' '.join(id_dict[id] for id in rev_data ))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================\n",
      "Sample = 6759 | Length = 248\n",
      "=================================================\n",
      "<START> trick or treat <UNK> review this zany romp of a film revolves around the 80's culture of heavy metal and horror movies two things which i love <UNK> so as you can imagine this movie <UNK> to me pretty easily plus for no apparent reason <UNK> <UNK> plays a preacher br br this film is about an <UNK> high school youth who like all us losers ended up <UNK> in a world of evil heavy metal his favorite <UNK> dies and of course is miraculously <UNK> by playing his latest <UNK> album backwards this allows the <UNK> singer to go around killing people with demons and sh t helping out br br okay it's pretty cheesy at times but you know what it's got a surprising number of good qualities decent acting including gene simmons as a radio dj pretty good special effects very brief nudity decent atmosphere all in all it's actually a decent horror film but what really sucks is the music ironic huh well this uber evil metal guy is one of the most obnoxious high pitched <UNK> <UNK> <UNK> rejects on the planet and the metal is little more than <UNK> 80's pop hair metal he hits all the <UNK> here from <UNK> around like a gay fairy to looking mean to screaming rock and roll in a pitch high enough to make king diamond <UNK> aside from that atrocious musical representation it's actually pretty good 7 10 br br www <UNK> com\n",
      "\n",
      "=================================================\n",
      "Sample = 6073 | Length = 160\n",
      "=================================================\n",
      "<START> don't spend your money or your time on this pitiful piece of film in the <UNK> of cinematography when every third word is devoted to foul language and there is no real plot as well as having a cast of old actors who are still giving the same dated performances from the past and have not evolved in their careers leaves a lot to be said i was expecting something better from award winning actor <UNK> del toro the vision that others may have of <UNK> will be <UNK> distorted by such trash as <UNK> a foul word at a given moment in a film may be used to emphasize a given point of view and may even be funny or sad depending on its context see the movie elsa and fred for example but it should not <UNK> the plot the movie is a total embarrassment and there was absolutely nothing funny or even cute about this film\n"
     ]
    }
   ],
   "source": [
    " # Print random reviews\n",
    "rev_n = 2\n",
    "for i in np.random.randint(0, len(trainX), rev_n):\n",
    "    print_rev(trainX[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Data before using it in the NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way to  ensure compatibility with the modelling structures is to first process the data before it is to be used in the neural network. The processing required is that the reviews need to be truncated to 500 words and any reviews shorter are to be padded. This is to ensure so that all of the data is of a similar size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing data\n",
    "trainX_p = pad_sequences(trainX, maxlen = 500, value = 0)\n",
    "testX_p = pad_sequences(testX, maxlen = 500, value = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "np.random.seed(1984)\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 20, input_length = 500))\n",
    "model.add(LSTM(32, return_sequences = True))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dropout(0.20))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first layer of the neutral network  is the Embedding layer. This layer enables the neural network to operate on text data that are converted to integers. LSTM layers  allow the recurrence required in the RNN. Dropout was used to assist in preventing the overfitting of the model.\n",
    "\n",
    "The input to the model would be a vector of 500 integers as per the  data processing step. The output would be a number between 0 and 1 where 0 is a negative sentiment and 1 is a postive sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 500, 20)           200000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 500, 32)           6784      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 16)                3136      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 209,937\n",
      "Trainable params: 209,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 548s 22ms/sample - loss: 0.4694 - acc: 0.7712 - val_loss: 0.4278 - val_acc: 0.8130\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 683s 27ms/sample - loss: 0.4838 - acc: 0.7660 - val_loss: 0.3283 - val_acc: 0.8692\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 694s 28ms/sample - loss: 0.2612 - acc: 0.9013 - val_loss: 0.3220 - val_acc: 0.8755\n"
     ]
    }
   ],
   "source": [
    "# Compiles the model\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Provides a summary\n",
    "model.summary()\n",
    "\n",
    "# Model training\n",
    "epochist = model.fit(trainX_p, trainY, epochs = 3\n",
    "                     , verbose = True\n",
    "                     , validation_data = (testX_p, testY)\n",
    "                     , batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test results: \n",
      " ==> Loss: 0.322\n",
      " ==> Accuracy: 87.548%\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(testX_p, testY)\n",
    "Loss = np.round(results[0], 3)\n",
    "Acc = np.round(100*results[1], 3)\n",
    "print(f'Test results: \\n ==> Loss: {Loss}\\n ==> Accuracy: {Acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function the provides the model output for given riew\n",
    "def m_predict(review):\n",
    "    # Split review into words\n",
    "    split = review.lower().split()\n",
    "    \n",
    "    # Convert words to integers using word_to_id dictionary\n",
    "    ids = []\n",
    "    for k in split:\n",
    "        if word_dict.get(k) == None:\n",
    "            ids.append(2)\n",
    "        else:\n",
    "            ids.append(word_dict.get(k))\n",
    "            \n",
    "    # Pad and truncate to input length\n",
    "    ids_p = pad_sequences(np.array(list([ids])), maxlen = 500, value = 0)\n",
    "    \n",
    "    # Use model\n",
    "    score = model.predict(ids_p)\n",
    "    \n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This movie is good <==> [[0.47562233]] <==> Good Sentiment\n",
      "This movie is not good <==> [[0.39087367]] <==> Bad Sentiment\n",
      "This movie was good <==> [[0.40771827]] <==> Good Sentiment\n",
      "This movie was not good <==> [[0.33134705]] <==> Bad Sentiment\n",
      "This movie is bad <==> [[0.22538441]] <==> Bad Sentiment\n",
      "This movie is not bad <==> [[0.20132266]] <==> Bad Sentiment\n",
      "This movie was bad <==> [[0.20304897]] <==> Bad Sentiment\n",
      "This movie was not bad <==> [[0.17836869]] <==> Bad Sentiment\n",
      "An interesting study in death by boredom <==> [[0.19303657]] <==> Bad Sentiment\n",
      "Fascinating and beautiful <==> [[0.81232333]] <==> Good Sentiment\n",
      "The movie is great <==> [[0.6603089]] <==> Good Sentiment\n",
      "The movie is not great <==> [[0.56914]] <==> Good Sentiment\n"
     ]
    }
   ],
   "source": [
    "# Test model with self-defined examples\n",
    "\n",
    "sample = ['This movie is good'\n",
    "            ,'This movie is not good'\n",
    "            ,'This movie was good'\n",
    "            ,'This movie was not good'\n",
    "            , 'This movie is bad'\n",
    "            , 'This movie is not bad'\n",
    "            , 'This movie was bad'\n",
    "            , 'This movie was not bad'\n",
    "            , 'An interesting study in death by boredom'\n",
    "            , 'Fascinating and beautiful'\n",
    "            , 'The movie is great'\n",
    "            , 'The movie is not great'\n",
    "]\n",
    "bench = 0.4\n",
    "for s in sample:\n",
    "    score = m_predict(s)\n",
    "    \n",
    "    if score > bench:\n",
    "        sent = 'Good'\n",
    "    else:\n",
    "        sent ='Bad'\n",
    "        \n",
    "    print(f'{s} <==> {score} <==> {sent} Sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various reviews were passed through the model. The main issue with the prediction of the model is that negatives are not handled consistently 'not good' is correctly identified as bad but 'not bad' is  identified as bad and 'not great' is  identified as good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
